                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.0529,                   0.39,                      1,                 1.0048,             0.00023721,             0.00023721,             0.00023721
                      2,                0.74904,                0.69667,                      1,                0.85819,             0.00045169,             0.00045169,             0.00045169
                      3,                0.62913,                0.79833,                      1,                 0.7688,              0.0006426,              0.0006426,              0.0006426
                      4,                0.58119,                0.89333,                      1,                0.71497,             0.00060797,             0.00060797,             0.00060797
                      5,                 0.5003,                0.58833,                      1,                0.87373,             0.00057263,             0.00057263,             0.00057263
                      6,                0.47672,                   0.86,                      1,                0.74474,             0.00053728,             0.00053728,             0.00053728
                      7,                0.45109,                0.90167,                      1,                0.68752,             0.00050194,             0.00050194,             0.00050194
                      8,                 0.4211,                0.89833,                      1,                0.69105,              0.0004666,              0.0004666,              0.0004666
                      9,                 0.4055,                0.89333,                      1,                0.69243,             0.00043126,             0.00043126,             0.00043126
                     10,                0.39582,                0.89667,                      1,                0.68569,             0.00039591,             0.00039591,             0.00039591
                     11,                0.38006,                  0.905,                      1,                0.68053,             0.00036057,             0.00036057,             0.00036057
                     12,                0.37305,                0.90333,                      1,                0.67969,             0.00032523,             0.00032523,             0.00032523
                     13,                0.34294,                0.85667,                      1,                0.71712,             0.00028988,             0.00028988,             0.00028988
                     14,                0.28344,                   0.97,                      1,                0.59867,             0.00025454,             0.00025454,             0.00025454
                     15,                0.22196,                  0.975,                      1,                0.59513,              0.0002192,              0.0002192,              0.0002192
                     16,                0.20743,                   0.97,                      1,                 0.6111,             0.00018385,             0.00018385,             0.00018385
                     17,                0.18518,                   0.98,                      1,                0.58836,             0.00014851,             0.00014851,             0.00014851
                     18,                0.17228,                0.97833,                      1,                0.58719,             0.00011317,             0.00011317,             0.00011317
                     19,                0.16228,                0.93333,                      1,                0.63416,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.15221,                   0.98,                      1,                0.58262,             4.2483e-05,             4.2483e-05,             4.2483e-05
